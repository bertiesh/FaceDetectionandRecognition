# Benchmark Testing

This repository contains scripts and tools to benchmark the performance and accuracy of a face recognition system. The scripts automate testing tasks such as dataset preparation, bulk uploads, response time measurements, and accuracy evaluations.

---

## Dataset

The dataset for testing can be found at [Dataset](https://drive.google.com/file/d/1dpfTxxAbM-3StVNCsA6qQyYNhhlsfPOu/view?usp=sharing).

---

## Folder Structure
- **`test_data_setup.py`**  
  Prepares the test dataset by randomly selecting one image per person for upload and one image for testing. The input directory should be a recursive directory such that each directory contains different images of the same person. It outputs two directories:
    - `sample_database directory`: Contains images to be uploaded to the database.
    - `sample_queries directory`: Contains query images used for face recognition accuracy testing.

Note: One such pair of sample database and queries directories have already been created for testing (available in the dataset download mentioned above).

- **`run_bulk_upload.sh`**  
  Starts the server and uploads images from the `sample_database directory` to a database named `sample_db`, measuring the time taken for the operation.

- **`run_face_find_time.sh`**  
  Starts the server and tests the face recognition function by running a single query image against the database, measuring the time taken to return results.

- **`run_face_find_accuracy.sh`**  
  Starts the server and evaluates the face recognition system. It tests the face recognition function on all images in the `sample_queries directory` one by one, saving the results to a CSV file.

- **`test_data_metrics.py`**  
  Analyzes the output CSV file generated by `run_face_find_accuracy.sh` to calculate and return the accuracy metrics for the face recognition system.

- **`edgecase_testing.py`**
  A script to test edge cases of a face recognition system allowing us to find reasons for failure. It visualizes detected faces by drawing bounding boxes on images and verifies the similarity between two images, providing the distance and the metric used for comparison. 
---

## Instructions to Run Accuracy Testing
1. **Prepare Dataset**
    - Download the dataset containing multiple directories (each directory represents a person and contains their images) from the link under the [Dataset](#dataset) section.

   > [!NOTE]\
   > *All the code below should be executed from the `benchmark_testing` directory.*
   > Make sure to execute all .sh files using git bash.

2. **Run Test Data Setup (Optional)**
    - Replace the directory names in the `test_data_setup.py` file with appropriate directory locations.
    - Execute `test_data_setup.py` to create the `sample_database directory` and `sample_queries directory`.

    ```
    python test_data_setup.py
    ```

3. **Run Bulk Upload and Measure Upload Time**
    - Add database directory to .env file in the main root of the project (e.g. ./FaceDetectionandRecognition/.env) with the name DATABASE_DIRECTORY
    - Execute `run_bulk_upload.sh <database_name>` to upload images to the database. Inserting the exact name of the database as the first argument.

    ```
    ./run_bulk_upload.sh
    ```

4. **Run Face Find and Measure Search Time**
    - Replace the directory names in the `run_face_find_time.sh` file with appropriate directory locations.
    - Execute `run_face_find_time.sh` to measure the response time of the face recognition system for a single query.

    ```
    ./run_face_find_time.sh
    ```

    - Alternatively, run `

5. **Run Face Find and Measure Accuracy**
    - Replace the directory names in the `run_face_find_accuracy.sh` file with appropriate directory locations.
    - Execute `run_face_find_accuracy.sh` to create output csv.

   ```
   ./run_face_find_accuracy.sh
   ```

    - Use `test_data_metrics.py` to analyze the accuracy of the face recognition system.

    ```
    python test_data_metrics.py
    ```

6. **Visualize face recognition results**
- Replace the directory names in the `edgecase_testing.py` file with appropriate image paths.
- Execute `edgecase_testing.py` to visualize the results of the face recognition system.

  ```
  python edgecase_testing.py
  ```

## Instructions to Run Precision and Recall Testing
1. **Prepare Dataset**
    - Download the dataset containing multiple directories (each directory represents a person and contains their images) from the link under the [Dataset](#dataset) section.

   > [!NOTE]\
   > *All the code below should be executed from the `benchmark_testing` directory.*
   > Make sure to execute all .sh files using git bash.

2. **Run Test Data Setup (Optional)**
    - Replace the directory names in the `test_data_setup.py` file with appropriate directory locations.
    - Execute `test_data_setup.py` to create the `sample_database directory` and `sample_queries directory`.

    ```
    python test_data_setup.py
    ```

3. **Run Bulk Upload**
    - Create a `new_sample_database directory` that contains only the first half of the images in the original `sample_database directory`.
    - Add database directory to .env file in the main root of the project (e.g. ./FaceDetectionandRecognition/.env) with the name DATABASE_DIRECTORY
    - Execute `run_bulk_upload.sh <database_name>` to upload images to the database. Inserting the exact name of the database as the first argument

    ```
    ./run_bulk_upload.sh
    ```

4. **Run Face Find and Measure Accuracy**
    - Replace the directory names in the `run_face_find_accuracy.sh` file with appropriate directory locations.
    - Replace the similarity threshold with `0.02` increments for every run of Face Find.
    - Execute `run_face_find_accuracy.sh` to create output csv for each similarity threshold.

   ```
   ./run_face_find_accuracy.sh
   ```

    - Use `test_data_metrics_confusion_matrix.py` to analyze the precision and recall for each similarity threshold.

    ```
    python test_data_metrics.py
    ```

5. **Visualize the ROC curve**
- The confusion matrix from the above can be used to measure tpr and fpr for each threshold.
- Use this to plot the ROC curve.


## Instructions to Run All Benchmark Testing 
1. **Prepare Dataset**
    - Download the dataset containing multiple directories (each directory represents a person and contains their images) from the link under the [Dataset](#dataset) section.

   > [!NOTE]\
   > *All the code below should be executed from the `benchmark_testing` directory.*
   > Make sure to execute all .sh files using git bash.

2. **Run Bulk Upload**
    - Add database directory to .env file in the main root of the project (e.g. `./FaceDetectionandRecognition/.env`) with the name DATABASE_DIRECTORY
    - Execute `run_bulk_upload.sh <database_name>` to upload images to the database. Inserting the exact name of the database as the first argument (probably including the current model being used which is specified under `model_name` in `./FaceDetectionandRecognition/src/facematch/config/model_config.json`).
    - repeat the above after changing `model_name` to `Facenet`, then `VGG-Face`. There should now be three databases, one for each model.

    ```
    ./run_bulk_upload.sh <database_name>
    ```

4. **Run Face Find Benchmark**
    - Add `SAMPLE_QUERIES_DIRECTORY` to the .env file as the path to the folder containing all the query images
    - Add `OUTPUT_CSV_DIRECTORY` to the .env file as the path to where the output csv files containing matches for each query image given a specific model and similarity threshold should be outputted.
    - Add `OUTPUT_CSV_PATH` to the .env file as `OUTPUT_CSV_DIRECTORY`+ the beginning of a file name, e.g:

      ```
        OUTPUT_CSV_DIRECTORY="<project directory>\\benchmark_testing\\LFWdataset"
        OUTPUT_CSV_PATH="${OUTPUT_CSV_DIRECTORY}\\output"
      ```

    - Given this setup, files will be outputted with the name output_ArcFace_0.5.csv given ArcFace is the model used and 0.5 is the similarity threshold.
    - Execute `run_face_find_benchmark.sh <db_name> <start_index> <num of images> <model>` to create an output csv for each similarity threshold.
    - Repeat the above changing `<model>` to `Facenet`, then `VGG-Face` and `<db_name>` to the database name of each respective model

      ```
        ./run_face_find_accuracy.sh
      ```

    - Use `test_data_metrics_confusion_matrix.py` to analyze the precision and recall for each similarity threshold.

4. **Run Test Data Metrics Benchmark**
    - Add `BENCHMARK_RESULTS_PATH` to the .env file as the path to where the output .csv files should be stored plus a beginning name of a possible csv file, e.g. `<output directory>\\face_match_benchmark_results`

    - Use `test_data_metrics_benchmark.py` to output benchmark results for top-1, 5 and 10 accuracies to separate .csv files.

    ```
    python test_data_benchmark.py
    ```